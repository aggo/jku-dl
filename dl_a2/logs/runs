C:\Users\agoia\AppData\Local\Continuum\Anaconda2\python.exe C:/Users/agoia/Dropbox/Projects/JKU/jku-dl/dl_a2/src/skeleton_with_logging.py
Using Theano backend.
Using gpu device 0: GeForce GT 730M (CNMeM is enabled with initial size: 75.0% of memory, cuDNN not available)
from Best Practices for Convolutional Neural Networks Applied to Visual Document AnalysisPatrice Y. Simard, Dave Steinkraus, John C. Platt
Using validation set instead of the actual testset
(10000L, 1L, 28L, 28L)
Train on 10000 samples, validate on 2000 samples
Epoch 1/12
10000/10000 [==============================] - 5s - loss: 1.4454 - acc: 0.5238 - val_loss: 1.2526 - val_acc: 0.5905
Epoch 2/12
10000/10000 [==============================] - 5s - loss: 0.7036 - acc: 0.7775 - val_loss: 0.8506 - val_acc: 0.7205
Epoch 3/12
10000/10000 [==============================] - 5s - loss: 0.5365 - acc: 0.8307 - val_loss: 0.6434 - val_acc: 0.7990
Epoch 4/12
10000/10000 [==============================] - 5s - loss: 0.4516 - acc: 0.8625 - val_loss: 0.5521 - val_acc: 0.8275
Epoch 5/12
10000/10000 [==============================] - 5s - loss: 0.3939 - acc: 0.8775 - val_loss: 0.5367 - val_acc: 0.8195
Epoch 6/12
10000/10000 [==============================] - 5s - loss: 0.3420 - acc: 0.8919 - val_loss: 0.4359 - val_acc: 0.8615
Epoch 7/12
10000/10000 [==============================] - 5s - loss: 0.3073 - acc: 0.9040 - val_loss: 0.4722 - val_acc: 0.8495
Epoch 8/12
10000/10000 [==============================] - 5s - loss: 0.2732 - acc: 0.9161 - val_loss: 0.6280 - val_acc: 0.7950
Epoch 9/12
10000/10000 [==============================] - 5s - loss: 0.2463 - acc: 0.9227 - val_loss: 0.5095 - val_acc: 0.8435
Epoch 10/12
10000/10000 [==============================] - 5s - loss: 0.2229 - acc: 0.9312 - val_loss: 0.4332 - val_acc: 0.8645
Epoch 11/12
10000/10000 [==============================] - 5s - loss: 0.2045 - acc: 0.9359 - val_loss: 0.3860 - val_acc: 0.8775
Epoch 12/12
10000/10000 [==============================] - 5s - loss: 0.1837 - acc: 0.9443 - val_loss: 0.4397 - val_acc: 0.8660
YAML representation:
class_name: Sequential
config:
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    batch_input_shape: !!python/tuple [null, 1, !!python/long '28', !!python/long '28']
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    input_dtype: float32
    name: convolution2d_1
    nb_col: 5
    nb_filter: 5
    nb_row: 5
    subsample: &id001 !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_2
    nb_col: 5
    nb_filter: 50
    nb_row: 5
    subsample: *id001
    trainable: true
- class_name: MaxPooling2D
  config:
    border_mode: valid
    dim_ordering: th
    name: maxpooling2d_1
    pool_size: &id002 !!python/tuple [2, 2]
    strides: *id002
    trainable: true
- class_name: Flatten
  config: {name: flatten_1, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: relu, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_1, output_dim: 100, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: softmax, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_2, output_dim: 10, trainable: true}
keras_version: 1.0.3
loss: str
optimizer: {epsilon: 1.0e-08, lr: 1.0, name: Adadelta, rho: 0.95}
sample_weight_mode: null

Test score: 0.439739082277
Test accuracy: 0.866
Done. ================================================


Process finished with exit code 0
