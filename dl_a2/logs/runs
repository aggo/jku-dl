C:\Users\agoia\AppData\Local\Continuum\Anaconda2\python.exe C:/Users/agoia/Dropbox/Projects/JKU/jku-dl/dl_a2/src/skeleton_with_logging.py
Using Theano backend.
Using gpu device 0: GeForce GT 730M (CNMeM is enabled with initial size: 75.0% of memory, cuDNN not available)
Using validation set instead of the actual testset
(10000L, 1L, 28L, 28L)
Train on 10000 samples, validate on 2000 samples
Epoch 1/12
10000/10000 [==============================] - 22s - loss: 1.3391 - acc: 0.5524 - val_loss: 0.8263 - val_acc: 0.7180
Epoch 2/12
10000/10000 [==============================] - 22s - loss: 0.5665 - acc: 0.8232 - val_loss: 0.6677 - val_acc: 0.7835
Epoch 3/12
10000/10000 [==============================] - 22s - loss: 0.4136 - acc: 0.8727 - val_loss: 0.6096 - val_acc: 0.8000
Epoch 4/12
10000/10000 [==============================] - 22s - loss: 0.3267 - acc: 0.8964 - val_loss: 0.4722 - val_acc: 0.8465
Epoch 5/12
10000/10000 [==============================] - 22s - loss: 0.2633 - acc: 0.9152 - val_loss: 0.3269 - val_acc: 0.8950
Epoch 6/12
10000/10000 [==============================] - 22s - loss: 0.2166 - acc: 0.9290 - val_loss: 0.3632 - val_acc: 0.8865
Epoch 7/12
10000/10000 [==============================] - 22s - loss: 0.1768 - acc: 0.9445 - val_loss: 0.3374 - val_acc: 0.8895
Epoch 8/12
10000/10000 [==============================] - 22s - loss: 0.1469 - acc: 0.9518 - val_loss: 0.3399 - val_acc: 0.8835
Epoch 9/12
10000/10000 [==============================] - 22s - loss: 0.1174 - acc: 0.9642 - val_loss: 0.4175 - val_acc: 0.8715
Epoch 10/12
10000/10000 [==============================] - 22s - loss: 0.0946 - acc: 0.9708 - val_loss: 0.3284 - val_acc: 0.8950
Epoch 11/12
10000/10000 [==============================] - 22s - loss: 0.0750 - acc: 0.9770 - val_loss: 0.3146 - val_acc: 0.9105
Epoch 12/12
10000/10000 [==============================] - 22s - loss: 0.0587 - acc: 0.9832 - val_loss: 0.2939 - val_acc: 0.9155
YAML representation:
class_name: Sequential
config:
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    batch_input_shape: !!python/tuple [null, 1, !!python/long '28', !!python/long '28']
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    input_dtype: float32
    name: convolution2d_1
    nb_col: 5
    nb_filter: 20
    nb_row: 5
    subsample: &id001 !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_2
    nb_col: 5
    nb_filter: 50
    nb_row: 5
    subsample: *id001
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_3
    nb_col: 5
    nb_filter: 50
    nb_row: 5
    subsample: *id001
    trainable: true
- class_name: MaxPooling2D
  config:
    border_mode: valid
    dim_ordering: th
    name: maxpooling2d_1
    pool_size: &id002 !!python/tuple [2, 2]
    strides: *id002
    trainable: true
- class_name: Flatten
  config: {name: flatten_1, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: relu, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_1, output_dim: 100, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: softmax, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_2, output_dim: 10, trainable: true}
keras_version: 1.0.3
loss: str
optimizer: {epsilon: 1.0e-08, lr: 1.0, name: Adadelta, rho: 0.95}
sample_weight_mode: null

Test score: 0.293860707581
Test accuracy: 0.9155
Done. ================================================


Process finished with exit code 0
