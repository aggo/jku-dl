C:\Users\agoia\AppData\Local\Continuum\Anaconda2\python.exe C:/Users/agoia/Dropbox/Projects/JKU/jku-dl/dl_a2/src/skeleton_with_logging.py
Using Theano backend.
Using gpu device 0: GeForce GT 730M (CNMeM is enabled with initial size: 75.0% of memory, cuDNN not available)
Using validation set instead of the actual testset
(10000L, 1L, 28L, 28L)
Train on 10000 samples, validate on 2000 samples
Epoch 1/12
10000/10000 [==============================] - 43s - loss: 1.3381 - acc: 0.5348 - val_loss: 0.5377 - val_acc: 0.8430
Epoch 2/12
10000/10000 [==============================] - 43s - loss: 0.6393 - acc: 0.8059 - val_loss: 0.4048 - val_acc: 0.8830
Epoch 3/12
10000/10000 [==============================] - 43s - loss: 0.4608 - acc: 0.8632 - val_loss: 0.3328 - val_acc: 0.9055
Epoch 4/12
10000/10000 [==============================] - 42s - loss: 0.3789 - acc: 0.8909 - val_loss: 0.3118 - val_acc: 0.9130
Epoch 5/12
10000/10000 [==============================] - 42s - loss: 0.3334 - acc: 0.9048 - val_loss: 0.2943 - val_acc: 0.9145
Epoch 6/12
10000/10000 [==============================] - 43s - loss: 0.3055 - acc: 0.9164 - val_loss: 0.2943 - val_acc: 0.9245
Epoch 7/12
10000/10000 [==============================] - 43s - loss: 0.2797 - acc: 0.9234 - val_loss: 0.3060 - val_acc: 0.9130
Epoch 8/12
10000/10000 [==============================] - 42s - loss: 0.2671 - acc: 0.9310 - val_loss: 0.2756 - val_acc: 0.9260
Epoch 9/12
10000/10000 [==============================] - 42s - loss: 0.2652 - acc: 0.9325 - val_loss: 0.3087 - val_acc: 0.9250
Epoch 10/12
10000/10000 [==============================] - 43s - loss: 0.2475 - acc: 0.9357 - val_loss: 0.3164 - val_acc: 0.9225
Epoch 11/12
10000/10000 [==============================] - 43s - loss: 0.2528 - acc: 0.9363 - val_loss: 0.3784 - val_acc: 0.9160
Epoch 12/12
10000/10000 [==============================] - 43s - loss: 0.2569 - acc: 0.9401 - val_loss: 0.3876 - val_acc: 0.9180
YAML representation:
class_name: Sequential
config:
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    batch_input_shape: !!python/tuple [null, 1, !!python/long '28', !!python/long '28']
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    input_dtype: float32
    name: convolution2d_1
    nb_col: 5
    nb_filter: 20
    nb_row: 5
    subsample: &id002 !!python/tuple [1, 1]
    trainable: true
- class_name: MaxPooling2D
  config:
    border_mode: valid
    dim_ordering: th
    name: maxpooling2d_1
    pool_size: &id001 !!python/tuple [2, 2]
    strides: *id001
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_2
    nb_col: 5
    nb_filter: 100
    nb_row: 5
    subsample: *id002
    trainable: true
- class_name: MaxPooling2D
  config:
    border_mode: valid
    dim_ordering: th
    name: maxpooling2d_2
    pool_size: &id003 !!python/tuple [2, 2]
    strides: *id003
    trainable: true
- class_name: Flatten
  config: {name: flatten_1, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: relu, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_1, output_dim: 120, trainable: true}
- class_name: Dropout
  config: {name: dropout_1, p: 0.25, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: relu, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_2, output_dim: 84, trainable: true}
- class_name: Dropout
  config: {name: dropout_2, p: 0.5, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: softmax, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_3, output_dim: 10, trainable: true}
keras_version: 1.0.3
loss: str
optimizer: {epsilon: 1.0e-08, lr: 1.0, name: Adadelta, rho: 0.95}
sample_weight_mode: null

Test score: 0.387601674184
Test accuracy: 0.918
Done. ================================================
