C:\Users\agoia\AppData\Local\Continuum\Anaconda2\python.exe C:/Users/agoia/Dropbox/Projects/JKU/jku-dl/dl_a2/src/skeleton_with_logging.py
Using Theano backend.
Using gpu device 0: GeForce GT 730M (CNMeM is enabled with initial size: 75.0% of memory, cuDNN not available)
Using validation set instead of the actual testset
(10000L, 1L, 28L, 28L)
Train on 10000 samples, validate on 2000 samples
Epoch 1/12
10000/10000 [==============================] - 11s - loss: 1.3943 - acc: 0.5353 - val_loss: 1.0838 - val_acc: 0.6330
Epoch 2/12
10000/10000 [==============================] - 11s - loss: 0.6163 - acc: 0.8067 - val_loss: 0.6749 - val_acc: 0.7750
Epoch 3/12
10000/10000 [==============================] - 11s - loss: 0.4587 - acc: 0.8588 - val_loss: 0.5712 - val_acc: 0.8070
Epoch 4/12
10000/10000 [==============================] - 11s - loss: 0.3732 - acc: 0.8852 - val_loss: 0.6493 - val_acc: 0.7880
Epoch 5/12
10000/10000 [==============================] - 11s - loss: 0.3128 - acc: 0.9015 - val_loss: 0.3792 - val_acc: 0.8765
Epoch 6/12
10000/10000 [==============================] - 11s - loss: 0.2730 - acc: 0.9160 - val_loss: 0.3900 - val_acc: 0.8815
Epoch 7/12
10000/10000 [==============================] - 11s - loss: 0.2326 - acc: 0.9284 - val_loss: 0.4240 - val_acc: 0.8645
Epoch 8/12
10000/10000 [==============================] - 11s - loss: 0.2048 - acc: 0.9358 - val_loss: 0.3554 - val_acc: 0.8900
Epoch 9/12
10000/10000 [==============================] - 11s - loss: 0.1755 - acc: 0.9461 - val_loss: 0.3369 - val_acc: 0.8970
Epoch 10/12
10000/10000 [==============================] - 11s - loss: 0.1511 - acc: 0.9555 - val_loss: 0.3501 - val_acc: 0.8900
Epoch 11/12
10000/10000 [==============================] - 11s - loss: 0.1286 - acc: 0.9622 - val_loss: 0.3381 - val_acc: 0.8935
Epoch 12/12
10000/10000 [==============================] - 11s - loss: 0.1097 - acc: 0.9679 - val_loss: 0.3506 - val_acc: 0.8935
YAML representation:
class_name: Sequential
config:
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    batch_input_shape: !!python/tuple [null, 1, !!python/long '28', !!python/long '28']
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    input_dtype: float32
    name: convolution2d_1
    nb_col: 5
    nb_filter: 20
    nb_row: 5
    subsample: &id001 !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_2
    nb_col: 5
    nb_filter: 50
    nb_row: 5
    subsample: *id001
    trainable: true
- class_name: MaxPooling2D
  config:
    border_mode: valid
    dim_ordering: th
    name: maxpooling2d_1
    pool_size: &id002 !!python/tuple [2, 2]
    strides: *id002
    trainable: true
- class_name: Flatten
  config: {name: flatten_1, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: relu, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_1, output_dim: 100, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: softmax, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_2, output_dim: 10, trainable: true}
keras_version: 1.0.3
loss: str
optimizer: {epsilon: 1.0e-08, lr: 1.0, name: Adadelta, rho: 0.95}
sample_weight_mode: null

Test score: 0.350560325027
Test accuracy: 0.8935
Done. ================================================


Process finished with exit code 0
