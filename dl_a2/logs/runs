C:\Users\agoia\AppData\Local\Continuum\Anaconda2\python.exe C:/Users/agoia/Dropbox/Projects/JKU/jku-dl/dl_a2/src/skeleton_with_logging.py
Using Theano backend.
Using gpu device 0: GeForce GT 730M (CNMeM is enabled with initial size: 75.0% of memory, cuDNN not available)
from Best Practices for Convolutional Neural Networks Applied to Visual Document AnalysisPatrice Y. Simard, Dave Steinkraus, John C. Platt
Using validation set instead of the actual testset
(10000L, 1L, 28L, 28L)
Train on 10000 samples, validate on 2000 samples
Epoch 1/12
10000/10000 [==============================] - 11s - loss: 1.7609 - acc: 0.4189 - val_loss: 1.2475 - val_acc: 0.5915
Epoch 2/12
10000/10000 [==============================] - 11s - loss: 0.9030 - acc: 0.7354 - val_loss: 0.8400 - val_acc: 0.7465
Epoch 3/12
10000/10000 [==============================] - 11s - loss: 0.6952 - acc: 0.8006 - val_loss: 0.7015 - val_acc: 0.7900
Epoch 4/12
10000/10000 [==============================] - 11s - loss: 0.5828 - acc: 0.8341 - val_loss: 0.6103 - val_acc: 0.8135
Epoch 5/12
10000/10000 [==============================] - 11s - loss: 0.5017 - acc: 0.8606 - val_loss: 0.5569 - val_acc: 0.8345
Epoch 6/12
10000/10000 [==============================] - 11s - loss: 0.4454 - acc: 0.8751 - val_loss: 0.5381 - val_acc: 0.8395
Epoch 7/12
10000/10000 [==============================] - 11s - loss: 0.3989 - acc: 0.8903 - val_loss: 0.4817 - val_acc: 0.8600
Epoch 8/12
10000/10000 [==============================] - 11s - loss: 0.3615 - acc: 0.9027 - val_loss: 0.4408 - val_acc: 0.8665
Epoch 9/12
10000/10000 [==============================] - 11s - loss: 0.3274 - acc: 0.9099 - val_loss: 0.4754 - val_acc: 0.8525
Epoch 10/12
10000/10000 [==============================] - 11s - loss: 0.3012 - acc: 0.9173 - val_loss: 0.4456 - val_acc: 0.8590
Epoch 11/12
10000/10000 [==============================] - 11s - loss: 0.2757 - acc: 0.9258 - val_loss: 0.4934 - val_acc: 0.8480
Epoch 12/12
10000/10000 [==============================] - 11s - loss: 0.2528 - acc: 0.9314 - val_loss: 0.4046 - val_acc: 0.8740
YAML representation:
class_name: Sequential
config:
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    batch_input_shape: !!python/tuple [null, 1, !!python/long '28', !!python/long '28']
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    input_dtype: float32
    name: convolution2d_1
    nb_col: 5
    nb_filter: 20
    nb_row: 5
    subsample: &id001 !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: null
    activation: relu
    activity_regularizer: null
    b_constraint: null
    b_regularizer: null
    bias: true
    border_mode: valid
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_2
    nb_col: 5
    nb_filter: 50
    nb_row: 5
    subsample: *id001
    trainable: true
- class_name: MaxPooling2D
  config:
    border_mode: valid
    dim_ordering: th
    name: maxpooling2d_1
    pool_size: &id002 !!python/tuple [2, 2]
    strides: *id002
    trainable: true
- class_name: Flatten
  config: {name: flatten_1, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: sigmoid, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_1, output_dim: 100, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: softmax, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
    name: dense_2, output_dim: 10, trainable: true}
keras_version: 1.0.3
loss: str
optimizer: {epsilon: 1.0e-08, lr: 1.0, name: Adadelta, rho: 0.95}
sample_weight_mode: null

Test score: 0.404579951048
Test accuracy: 0.874
Done. ================================================


Process finished with exit code 0
